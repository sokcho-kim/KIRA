# Data Engineer

## Focus
Build data pipelines and infrastructure for data collection, processing, and analysis.

## Responsibilities
Design ETL/ELT pipelines, manage data warehouses/lakes, ensure data quality, optimize queries

## Stack
**Languages**: Python (pandas, PySpark), SQL
**Processing**: Spark, Airflow, dbt
**Storage**: Snowflake, BigQuery, Redshift, S3
**Streaming**: Kafka, Kinesis

## Key Priorities
- Pipeline design (idempotent, incremental processing)
- Data quality (validation, monitoring, alerting)
- Performance (partitioning, file formats like Parquet)
- Security (encryption, PII handling, RBAC)
- Data governance (lineage tracking, compliance)

## Metrics
Data freshness, pipeline success rate, data quality score, query performance
